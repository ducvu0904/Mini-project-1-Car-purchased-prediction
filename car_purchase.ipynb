{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e5c1df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   User ID          400 non-null    int64 \n",
      " 1   Gender           400 non-null    object\n",
      " 2   Age              400 non-null    int64 \n",
      " 3   EstimatedSalary  400 non-null    int64 \n",
      " 4   Purchased        400 non-null    int64 \n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 15.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['User ID', 'Gender', 'Age', 'EstimatedSalary', 'Purchased'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                                            #Logistic Regression\n",
    "# load data and inspect\n",
    "import pandas as pd \n",
    "#load and inspect data\n",
    "df = pd.read_csv(\"Social_Network_Ads.csv\")\n",
    "df.head()\n",
    "df.info()\n",
    "df.describe()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fac34da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender             int64\n",
      "Age                int64\n",
      "EstimatedSalary    int64\n",
      "Purchased          int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Age  EstimatedSalary  Purchased\n",
       "0       1   19            19000          0\n",
       "1       1   35            20000          0\n",
       "2       0   26            43000          0\n",
       "3       0   27            57000          0\n",
       "4       1   19            76000          0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop useless identifier\n",
    "df = df.drop(columns=['User ID'])\n",
    "df['Gender'] = df[\"Gender\"].map({\"Male\": 1, \"Female\": 0})\n",
    "\n",
    "print (df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f04d10cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((320, 3),\n",
       " (80, 3),\n",
       " Purchased\n",
       " 0    206\n",
       " 1    114\n",
       " Name: count, dtype: int64,\n",
       " Purchased\n",
       " 0    51\n",
       " 1    29\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#features/labels + train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[['Gender', 'Age', 'EstimatedSalary']]\n",
    "y = df['Purchased']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train.shape, X_test.shape, y_train.value_counts(), y_test.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87455ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.797     0.922     0.855        51\n",
      "           1      0.810     0.586     0.680        29\n",
      "\n",
      "    accuracy                          0.800        80\n",
      "   macro avg      0.803     0.754     0.767        80\n",
      "weighted avg      0.801     0.800     0.791        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluate model\n",
    "#1) Imports\n",
    "from sklearn.pipeline import make_pipeline                        #builds a sequence of steps\n",
    "from sklearn.preprocessing import StandardScaler                  #scales numeric feature\n",
    "from sklearn.linear_model import LogisticRegression               #simple classification model\n",
    "from sklearn.metrics import accuracy_score, classification_report #ways to measure performance\n",
    "# 2) Build a pipeline: [scale] -> [logistic regression]\n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(),                                   #scale features\n",
    "    LogisticRegression(random_state=42, max_iter=1000)  # the model\n",
    ")\n",
    "# 3) Train (fit) the model on the training set\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# 4) Use the trained model to predict on the unseen (20%) test set\n",
    "y_predict = pipe.predict(X_test)\n",
    "\n",
    "# 5) Evaluate: how many right?\n",
    "print (\"Accuracy:\", accuracy_score(y_test, y_predict))\n",
    "print (classification_report(y_test, y_predict, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "166df82e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Model performance\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConfusionMatrixDisplay, roc_auc_score, classification_report\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m#1) Predict class labels (0/1) and probabilities\u001b[39;00m\n\u001b[32m      6\u001b[39m y_pred = pipe.predict(X_test)                   \u001b[38;5;66;03m#class predictions\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\matplotlib\\pyplot.py:62\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_backend \u001b[38;5;28;01mas\u001b[39;00m get_backend, rcParams \u001b[38;5;28;01mas\u001b[39;00m rcParams\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cm \u001b[38;5;28;01mas\u001b[39;00m cm  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m style \u001b[38;5;28;01mas\u001b[39;00m style  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _pylab_helpers\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m interactive  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\matplotlib\\style\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m available, context, library, reload_library, use\n\u001b[32m      4\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mavailable\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlibrary\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mreload_library\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33muse\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\matplotlib\\style\\core.py:225\u001b[39m\n\u001b[32m    220\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m main_dict\n\u001b[32m    223\u001b[39m \u001b[38;5;66;03m# Load style library\u001b[39;00m\n\u001b[32m    224\u001b[39m \u001b[38;5;66;03m# ==================\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m225\u001b[39m _base_library = \u001b[43mread_style_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBASE_LIBRARY_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    226\u001b[39m library = {}\n\u001b[32m    227\u001b[39m available = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\matplotlib\\style\\core.py:203\u001b[39m, in \u001b[36mread_style_directory\u001b[39m\u001b[34m(style_dir)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m Path(style_dir).glob(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m*.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSTYLE_EXTENSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m warnings.catch_warnings(record=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m warns:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m         styles[path.stem] = \u001b[43m_rc_params_in_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m warns:\n\u001b[32m    205\u001b[39m         _log.warning(\u001b[33m'\u001b[39m\u001b[33mIn \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m, path, w.message)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\matplotlib\\__init__.py:906\u001b[39m, in \u001b[36m_rc_params_in_file\u001b[39m\u001b[34m(fname, transform, fail_on_error)\u001b[39m\n\u001b[32m    904\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmpl\u001b[39;00m\n\u001b[32m    905\u001b[39m rc_temp = {}\n\u001b[32m--> \u001b[39m\u001b[32m906\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_open_file_or_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfd\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\contextlib.py:141\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\matplotlib\\__init__.py:883\u001b[39m, in \u001b[36m_open_file_or_url\u001b[39m\u001b[34m(fname)\u001b[39m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    882\u001b[39m     fname = os.path.expanduser(fname)\n\u001b[32m--> \u001b[39m\u001b[32m883\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    884\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:312\u001b[39m, in \u001b[36mBufferedIncrementalDecoder.__init__\u001b[39m\u001b[34m(self, errors)\u001b[39m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mBufferedIncrementalDecoder\u001b[39;00m(IncrementalDecoder):\n\u001b[32m    307\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    308\u001b[39m \u001b[33;03m    This subclass of IncrementalDecoder can be used as the baseclass for an\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    incremental decoder if the decoder must be able to handle incomplete\u001b[39;00m\n\u001b[32m    310\u001b[39m \u001b[33;03m    byte sequences.\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, errors=\u001b[33m'\u001b[39m\u001b[33mstrict\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    313\u001b[39m         IncrementalDecoder.\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, errors)\n\u001b[32m    314\u001b[39m         \u001b[38;5;66;03m# undecoded input that is kept between calls to decode()\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Model performance\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, roc_auc_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#1) Predict class labels (0/1) and probabilities\n",
    "y_pred = pipe.predict(X_test)                   #class predictions\n",
    "y_proba = pipe.predict_proba(X_test)[:,1]       # probability of class \"1\"\n",
    "\n",
    "#2) Basic scores\n",
    "print (\"Accuracy:\", (y_pred == y_test).mean())\n",
    "print (\"AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print (classification_report(y_test, y_pred, digits = 3))\n",
    "\n",
    "#3) Confusion matrix\n",
    "ConfusionMatrixDisplay.from_estimator(pipe, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e303dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold=0.3 precision=0.650 recall=0.897 f1=0.754\n",
      "threshold=0.5 precision=0.810 recall=0.586 f1=0.680\n",
      "threshold=0.7 precision=0.875 recall=0.483 f1=0.622\n"
     ]
    }
   ],
   "source": [
    "# tune threshold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# probabilities for buyer (class 1)\n",
    "y_pred = pipe.predict_proba(X_test)[:,1]\n",
    "\n",
    "def predict_with_threshold(proba, t):\n",
    "    return (proba >= t).astype(int)\n",
    "\n",
    "#try new thresold\n",
    "for t in [0.3, 0.5, 0.7]:\n",
    "    y_pred_thres = predict_with_threshold(y_proba, t)\n",
    "    prec = precision_score(y_test, y_pred_thres)\n",
    "    rec = recall_score(y_test, y_pred_thres)\n",
    "    f1 = f1_score(y_test, y_pred_thres)\n",
    "    print (f\"threshold={t:.1f} precision={prec:.3f} recall={rec:.3f} f1={f1:.3f}\")\n",
    "    #result\n",
    "# threshold=0.3 precision=0.650 recall=0.897 f1=0.754\n",
    "# threshold=0.5 precision=0.810 recall=0.586 f1=0.680\n",
    "# threshold=0.7 precision=0.875 recall=0.483 f1=0.622\n",
    "#=> threshold = 0.3: best f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7417ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          metric  value\n",
       " 0   accuracy:o,5  0.800\n",
       " 1  precision:0.5  0.810\n",
       " 2     recall:0.5  0.586\n",
       " 3         f1:0.5  0.680\n",
       " 4            auc  0.908\n",
       " 5  precision:0.3  0.650\n",
       " 6     recall:0.3  0.897\n",
       " 7         f1:0.3  0.754,\n",
       " array([[37, 14],\n",
       "        [ 3, 26]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final report\n",
    " \n",
    "#a) import\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib as plt\n",
    "\n",
    "#base at 0.5\n",
    "y_pred_05 = pipe.predict(X_test)\n",
    "y_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#chosen threshold\n",
    "t= 0.3\n",
    "y_pred_thres_03 = (y_proba >= t).astype(int)\n",
    "\n",
    "report = pd.DataFrame({\n",
    "    \"metric\": [\"accuracy:o,5\", \"precision:0.5\", \"recall:0.5\", \"f1:0.5\",\"auc\",\n",
    "    f\"precision:{t}\", f\"recall:{t}\", f\"f1:{t}\"],\n",
    "    \"value\": [\n",
    "        accuracy_score(y_test, y_pred_05),\n",
    "        precision_score(y_test, y_pred_05),\n",
    "        recall_score(y_test, y_pred_05),\n",
    "        f1_score(y_test, y_pred_05),\n",
    "        roc_auc_score(y_test, y_proba),\n",
    "        precision_score(y_test, y_pred_thres_03),\n",
    "        recall_score(y_test, y_pred_thres_03),\n",
    "        f1_score(y_test, y_pred_thres_03)\n",
    "    ]\n",
    "})\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_thres_03)\n",
    "\n",
    "report.round(3), cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e2b9ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8625\n",
      "AUC     : 0.9350912778904664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.900     0.882     0.891        51\n",
      "           1      0.800     0.828     0.814        29\n",
      "\n",
      "    accuracy                          0.863        80\n",
      "   macro avg      0.850     0.855     0.852        80\n",
      "weighted avg      0.864     0.863     0.863        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "                                                    #Decision Tree\n",
    "#1) Import models and metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "#2) Create a tree\n",
    "tree = DecisionTreeClassifier(max_depth=4, random_state=42)   #max_depth limit how deep the tree can grow\n",
    "\n",
    "#3) Fit training data\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "#4) Predict unseen data\n",
    "tree_pred = tree.predict(X_test)\n",
    "tree_proba = tree.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#5) Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, tree_pred))\n",
    "print(\"AUC     :\", roc_auc_score(y_test, tree_proba))\n",
    "print(classification_report(y_test, tree_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5a7fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n",
      "Auc : 0.9540229885057471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.939     0.902     0.920        51\n",
      "           1      0.839     0.897     0.867        29\n",
      "\n",
      "    accuracy                          0.900        80\n",
      "   macro avg      0.889     0.899     0.893        80\n",
      "weighted avg      0.903     0.900     0.901        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#                                                      Random forest\n",
    "#1) import\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "#2) Create forest \n",
    "forest = RandomForestClassifier (\n",
    "    n_estimators= 300,             # forest has 500\n",
    "    max_depth =4,                  # max depth = 4\n",
    "    random_state=42)              \n",
    "\n",
    "#3) Fit data\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "#3) Predict \n",
    "fr_pred = forest.predict(X_test)\n",
    "fr_proba = forest.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#4) Evaluate\n",
    "print (\"Accuracy:\", accuracy_score(y_test, fr_pred))\n",
    "print (\"Auc :\", roc_auc_score(y_test, fr_proba))\n",
    "print (classification_report(y_test, fr_pred, digits=3 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f144801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy (0.5)</th>\n",
       "      <th>precision (0.5)</th>\n",
       "      <th>recall (0.5)</th>\n",
       "      <th>f1 (0.5)</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tree Decision</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  accuracy (0.5)  ...  f1 (0.5)    auc\n",
       "1        Random forest           0.900  ...     0.867  0.954\n",
       "2        Tree Decision           0.862  ...     0.814  0.935\n",
       "3  Logistic Regression           0.800  ...     0.680  0.908\n",
       "\n",
       "[3 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FINAL REPORT\n",
    "\n",
    "#1) import\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"accuracy (0.5)\": accuracy_score(y_test, y_pred),\n",
    "        \"precision (0.5)\": precision_score(y_test, y_pred),\n",
    "        \"recall (0.5)\": recall_score(y_test, y_pred), \n",
    "        \"f1 (0.5)\": f1_score(y_test, y_pred),\n",
    "        \"auc\": roc_auc_score(y_test, y_proba)\n",
    "    }\n",
    "result = []\n",
    "result.append(evaluate_model(pipe, X_test, y_test, \"Logistic Regression\"))\n",
    "result.append(evaluate_model(tree, X_test, y_test, \"Tree Decision\"))\n",
    "result.append(evaluate_model(forest, X_test, y_test, \"Random forest\"))\n",
    "\n",
    "report = pd.DataFrame(result).sort_values(\"auc\", ascending = False).reset_index(drop=True).round(3)\n",
    "report.index = report.index + 1\n",
    "report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8488c72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy (0.5)</th>\n",
       "      <th>precision (0.5)</th>\n",
       "      <th>recall (0.5)</th>\n",
       "      <th>f1 (0.5)</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  accuracy (0.5)  ...  f1 (0.5)    auc\n",
       "1  Random forest             0.9  ...     0.867  0.954\n",
       "\n",
       "[1 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#                                                       Best model\n",
    "report.sort_values(\"auc\", ascending=False).head(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
